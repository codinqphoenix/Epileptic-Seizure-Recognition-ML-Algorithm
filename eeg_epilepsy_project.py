# -*- coding: utf-8 -*-
"""eeg epilepsy project

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1vA0BQDBD9_VrH8HxoKPRzi0OzQWOMYHG

This is a machine learning algorithm through artificial neural networks (ANN).
"""

# Commented out IPython magic to ensure Python compatibility.
# importing libraries
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import tensorflow as tf
import seaborn as sn
from sklearn.model_selection import train_test_split

# loading the dataset
!pip install kaggle

# Downloading dataset
!kaggle datasets download -d harunshimanto/epileptic-seizure-recognition

# Unzip the downloaded dataset
!unzip epileptic-seizure-recognition.zip

# Now try reading the CSV file from your local directory
dataset = pd.read_csv('Epileptic Seizure Recognition.csv') # Replace 'data.csv' with the actual CSV filename within the dataset
# %autosave 60

# allows us to view some of the data and check rows + columns
dataset.head()

# data pre-processing but since this is already pre-processed let's just double-check
dataset.isnull().sum()

# shows information about the data
print(dataset.info())
dataset.describe()

# converts seizure classes to binary
cols = dataset.columns
tgt = dataset.y
tgt[tgt>1]=0
ax = sn.countplot(tgt,label="Count")
non_seizure, seizure = tgt.value_counts()
print('The number of trials for the non-seizure class is:', non_seizure)
print('The number of trials for the seizure class is:', seizure)

# we'll drop unnamed column as it is of no use to us
dataset.drop(['Unnamed'], axis=1, inplace=True)

# selecting first and last column as again it is not helpful
data=pd.DataFrame(dataset.iloc[:,0:-1])
data.head()

from sklearn.preprocessing import StandardScaler
sc = StandardScaler()
# X_train = sc.fit_transform(X_train)
# X_test = sc.transform(X_test)
scaled_data = sc.fit_transform(data)

# assigning to X and y
X = scaled_data
y = dataset['y']

# splitting the data into train and test (30% data goes into test?)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3)
X_valid, X_test, y_valid, y_test = train_test_split(X_test, y_test, test_size = 0.2)




# building ann
ann = tf.keras.models.Sequential()
ann.add(tf.keras.layers.Dense(units = 9, activation = 'relu')) #First hidden layer
ann.add(tf.keras.layers.Dense(units = 9, activation = 'relu')) #Second hidden layer
ann.add(tf.keras.layers.Dense(units = 1, activation = 'sigmoid')) #Output layer

# compiling ann
ann.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])

# training ann
history = ann.fit(X, y, batch_size = 100, epochs = 50, validation_data=(X_valid, y_valid))

predictions = ann.predict(X_test) > 0.5

from sklearn.metrics import confusion_matrix, accuracy_score
cm = confusion_matrix(y_test, predictions)
print(cm)
print("The accuracy score is", accuracy_score(y_test, predictions) * 100, "%")

print("Printing the learning curve")
pd.DataFrame(history.history).plot(
    figsize=(8, 5), xlim=[0, 9], ylim=[0, 3], grid=True, xlabel="Epoch",
    style=["r--", "r--.", "b-", "b-*"])
plt.show()